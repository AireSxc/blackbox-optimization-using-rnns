{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "import gpfunctions as gp\n",
    "import lstm_model\n",
    "import benchmarkfunctions as bm\n",
    "import skopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOSS_FUNCS = ['MIN','SUMMIN']\n",
    "BASELINES = ['SKOPT', 'RANDOM']\n",
    "DIMS = [2,3,4,6]\n",
    "N_STEPS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FUNCTIONS = {\n",
    "    #TODO : 1d, 4d, 6d\n",
    "    '2d': bm.goldstein_price,\n",
    "    '2d_tf': bm.goldstein_price_tf,\n",
    "    '3d': bm.hartmann3,\n",
    "    '3d_tf': bm.hartmann3_tf,\n",
    "    '6d': bm.hartmann6,\n",
    "    '6d_tf': bm.hartmann6_tf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_y_from_skopt(dim, n_start_random=10, runs=10, func=None):\n",
    "    if func==None:\n",
    "        obj_func =  lambda x : float(FUNCTIONS['%dd'%(dim)](x))\n",
    "    else:\n",
    "        obj_func =  lambda x : float(func(x))\n",
    "    data = []\n",
    "    for i in range(runs):\n",
    "        res = skopt.gp_minimize(obj_func, [(-1.0, 1.0)]*dim, n_calls=N_STEPS+1, x0=[-1]*dim)\n",
    "        data.append(res.func_vals)\n",
    "    return np.mean(np.array(data),axis=0)\n",
    "\n",
    "def get_y_from_random(dim, steps, runs=10, func=None):\n",
    "    data = []\n",
    "    for i in range(runs):\n",
    "        x = np.random.uniform(-1,1,(dim,steps))\n",
    "        x[:, 0] = [-1]*dim\n",
    "        if func==None:\n",
    "            y = np.apply_along_axis(FUNCTIONS['%dd'%(dim)], 0, x)\n",
    "        else:\n",
    "            y = np.apply_along_axis(func, 0, x)\n",
    "        data.append(y.T)\n",
    "    return np.mean(np.array(data),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_y_from_lstm(kernel, dim, loss, func, n_steps=20, debug=False):\n",
    "    \n",
    "    model = utils.get_trained_model(dim=dim, kernel=kernel, loss=loss)    \n",
    "    starting_point = utils.loadConfig()['experiments']['%dD'%dim]['hyperparameters']['starting_point'][0]\n",
    "\n",
    "    model_params = lstm_model.load_model_params(model, debug=False)\n",
    "\n",
    "    res = None\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        lstm_params = {\n",
    "            'dim' : model_params['dim'],\n",
    "            'n_hidden': model_params['n_hidden'],\n",
    "            'forget_bias': model_params['forget_bias'],\n",
    "            'scope': model_params['scope']\n",
    "        }\n",
    "        cell, weights = lstm_model.get_lstm_weights(**lstm_params)\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_params['model_path'])\n",
    "\n",
    "        benchmark_samples_params = {\n",
    "            'f': func,\n",
    "            'cell': cell,\n",
    "            'weights': weights,\n",
    "            'dim': model_params['dim'],\n",
    "            'n_hidden': model_params['n_hidden'],\n",
    "            'n_steps': model_params['n_steps'],\n",
    "            'scope': model_params['scope'],\n",
    "            'batch_size': 1\n",
    "        }\n",
    "        \n",
    "        samples_benchmark_x, samples_benchmark_y, x_0 = lstm_model.apply_lstm_model(**benchmark_samples_params)\n",
    "    \n",
    "        feed_dict = {\n",
    "            x_0: np.array(starting_point).reshape(1,-1)\n",
    "        }\n",
    "        sample_y, sample_x = sess.run([samples_benchmark_y, samples_benchmark_x], feed_dict=feed_dict)\n",
    "        sample_y = np.array(sample_y).reshape(-1,1).T\n",
    "        sample_x = np.array(sample_x).reshape(-1,1, model_params['dim']).transpose((1,0,2)).reshape(-1,model_params['dim'])\n",
    "        return sample_y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_for_dim(dim):\n",
    "    data = {}\n",
    "    data['SKOPT']  = utils.min_up_to_k(get_y_from_skopt(dim))\n",
    "    data['RANDOM'] = utils.min_up_to_k(get_y_from_random(dim, steps = N_STEPS+1))\n",
    "    \n",
    "    for k in BASELINES:\n",
    "        plt.plot(data[k], label=k)\n",
    "        \n",
    "    for kernel in ['rbf', 'matern32']:\n",
    "        for loss in LOSS_FUNCS:\n",
    "            y = get_y_from_lstm(kernel, dim, loss, FUNCTIONS['%dd_tf'%(dim)])\n",
    "            y = utils.min_up_to_k(y)\n",
    "            plt.plot(y, label='LSTM-%s-%s'%(loss, kernel.upper()))\n",
    "        \n",
    "    xticks = range(0,N_STEPS+1,2)\n",
    "    plt.ylabel('Min Found')\n",
    "    plt.xlabel('Evaluation Step')\n",
    "    plt.xticks(xticks)\n",
    "    plt.ylim(-1)\n",
    "    plt.title('%dD' % dim)\n",
    "    plt.legend()\n",
    "    plt.plot()\n",
    "    \n",
    "#plot_for_dim(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_for_parabolasin(wiggle):\n",
    "    dim = 2\n",
    "    data = {}\n",
    "    data['SKOPT']  = utils.min_up_to_k(get_y_from_skopt(dim, func=lambda x : bm.parabolasin(x, wiggle)))\n",
    "    data['RANDOM'] = utils.min_up_to_k(get_y_from_random(dim, steps = N_STEPS+1, func= lambda x : bm.parabolasin(x, wiggle)))\n",
    "    \n",
    "    for k in BASELINES:\n",
    "        plt.plot(data[k], label=k)\n",
    "        \n",
    "    for kernel in ['rbf']:#, 'matern32']:\n",
    "        for loss in LOSS_FUNCS:\n",
    "            y = get_y_from_lstm(kernel, dim, loss, lambda x : bm.parabolasin_tf(x, wiggle))\n",
    "            y = utils.min_up_to_k(y)\n",
    "            plt.plot(y, label='LSTM-%s-%s'%(loss, kernel.upper()))\n",
    "        \n",
    "    xticks = range(0,N_STEPS+1,2)\n",
    "    plt.ylabel('Min Found')\n",
    "    plt.xlabel('Evaluation Step')\n",
    "    plt.xticks(xticks)\n",
    "    plt.ylim(-1)\n",
    "    plt.title('%dD' % dim)\n",
    "    plt.legend()\n",
    "    plt.plot()\n",
    "    \n",
    "plot_for_parabolasin(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_for_dim(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_for_dim(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "plt.figure(figsize=(15,4*2))\n",
    "for d in [2,3,3,6]:\n",
    "    plt.subplot(2,2,count + 1 )\n",
    "    plot_for_dim(d)\n",
    "    count = count + 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
