{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poly(params,x):\n",
    "    return tf.reshape(tf.reduce_sum(tf.multiply(x ** np.linspace(0,degree-1,degree), params),axis = 1),[-1,1])\n",
    "\n",
    "def min_poly(params):\n",
    "    x_min = -params[0,1]/(2*params[0,2])\n",
    "    y_min = np.dot(x_min ** np.linspace(0,3-1,3), params.reshape(-1))\n",
    "    return y_min\n",
    "\n",
    "def min_many_poly(params):\n",
    "    s = 0\n",
    "    for i in range(n_train):\n",
    "        s += min_poly(params[i].reshape(1,3))     \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0389248212694\n"
     ]
    }
   ],
   "source": [
    "# Polynomial degree\n",
    "degree = 3\n",
    "n_train = 1\n",
    "n_hidden = 20\n",
    "\n",
    "# Generate Training Data\n",
    "f_train = np.random.uniform(size=(n_train,3))\n",
    "x_init = 0.5*np.ones((n_train,1))\n",
    "h_init = np.random.uniform(size=(n_train,n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f_train.shape)\n",
    "print(x_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Model\n",
    "\n",
    "n_hidden = 20\n",
    "\n",
    "x_0 = tf.placeholder(tf.float32, shape=[None,1])\n",
    "params = tf.placeholder(tf.float32, [None, degree])\n",
    "h_0 = tf.placeholder(tf.float32, [None, n_hidden])\n",
    "\n",
    "def rnn_cell(x,y,h):\n",
    "    W_1 = tf.Variable(tf.truncated_normal([2+n_hidden,60],stddev=0.5))\n",
    "    b_1 = tf.Variable(tf.constant(0.1, shape=[60]))\n",
    "\n",
    "    W_2 = tf.Variable(tf.truncated_normal([60,60],stddev=0.5))\n",
    "    b_2 = tf.Variable(tf.constant(0.1, shape=[60]))\n",
    "\n",
    "    W_3 = tf.Variable(tf.truncated_normal([60,1+n_hidden],stddev=0.5))\n",
    "    b_3 = tf.Variable(tf.constant(0.1, shape=[1+n_hidden]))\n",
    "\n",
    "    z = tf.concat(1,[x, y, h])\n",
    "\n",
    "    h_1 = tf.tanh(tf.matmul(z, W_1) + b_1)\n",
    "    h_2 = tf.tanh(tf.matmul(h_1, W_2) + b_2)\n",
    "    out = tf.tanh(tf.matmul(h_2, W_3) + b_3)\n",
    "    \n",
    "    x_out, h_out = tf.split_v(value = out,size_splits=[1, n_hidden],split_dim=1)\n",
    "    \n",
    "    return x_out, h_out\n",
    "\n",
    "seq_length = 3\n",
    "    \n",
    "f = poly(params,x_0)\n",
    "\n",
    "x, h = rnn_cell(x_0,f, h_0) \n",
    "f = poly(params,x)\n",
    "\n",
    "f_sum = tf.reduce_sum(f)/seq_length\n",
    "\n",
    "for i in range(seq_length-1):\n",
    "    x, h = rnn_cell(x,f, h) \n",
    "    f = poly(params,x)\n",
    "\n",
    "    f_sum += tf.reduce_sum(f)/seq_length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'gradients_11/split_v_27_grad/concat:0' shape=(?, ?) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients_11/split_v_26_grad/concat:0' shape=(?, ?) dtype=float32>, None, None]\n",
      "[<tf.Tensor 'gradients_11/split_v_25_grad/concat:0' shape=(?, ?) dtype=float32>, None, None]\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.AdamOptimizer(0.001).minimize(f_sum)\n",
    "#train_step = tf.train.GradientDescentOptimizer(1.0).minimize(f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1076155]\n",
      "[-0.038818505]\n",
      "[-0.038598277]\n",
      "[-0.038924802]\n",
      "[-0.038924821]\n",
      "[-0.038924821]\n",
      "[-0.038924821]\n",
      "[-0.038924597]\n",
      "[-0.038924821]\n",
      "[-0.038924821]\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for i in range(epochs):\n",
    "    sess.run(train_step, feed_dict={params:f_train, x_0:x_init, h_0:h_init})\n",
    "    cost = sess.run([f_sum], feed_dict={params:f_train, x_0:x_init, h_0:h_init})\n",
    "    if i% 100 == 0:\n",
    "        print(cost)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum achieveable value\n",
      "-0.0389248212694\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum achieveable value\")\n",
    "print(min_many_poly(f_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
